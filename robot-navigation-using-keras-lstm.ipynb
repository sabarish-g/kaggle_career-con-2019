{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['y_train.csv', 'sample_submission.csv', 'X_test.csv', 'X_train.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "3e9f07b1c5b3a9ba99acaa1184633502594f7f6e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('../input/X_train.csv')\n",
    "y_train = pd.read_csv('../input/y_train.csv')\n",
    "x_test = pd.read_csv('../input/X_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a3c6dc27883b09a90407edd0664721529e51c30a"
   },
   "source": [
    "For every series, we have 128 observations and hence the number of rows in the x_train and y_train do not match. We should pre-process the x_train appropirately to get it down to the same dimension as y_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "8950a33af285fb44af80cfcd7164e0d8d23d6453"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>measurement_number</th>\n",
       "      <th>orientation_X</th>\n",
       "      <th>orientation_Y</th>\n",
       "      <th>orientation_Z</th>\n",
       "      <th>orientation_W</th>\n",
       "      <th>angular_velocity_X</th>\n",
       "      <th>angular_velocity_Y</th>\n",
       "      <th>angular_velocity_Z</th>\n",
       "      <th>linear_acceleration_X</th>\n",
       "      <th>linear_acceleration_Y</th>\n",
       "      <th>linear_acceleration_Z</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>series_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           row_id          ...            linear_acceleration_Z\n",
       "series_id                  ...                                 \n",
       "0             128          ...                              128\n",
       "1             128          ...                              128\n",
       "2             128          ...                              128\n",
       "\n",
       "[3 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.groupby('series_id').count().head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "9531f2cf37bcc3621644957e29471b131984e86e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>surface</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>fine_concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>concrete</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   series_id  group_id        surface\n",
       "0          0        13  fine_concrete\n",
       "1          1        31       concrete\n",
       "2          2        20       concrete"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "aadb314ad994b8763381e8093f95cc957107020e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13, 31, 20, 22,  1, 34, 33, 11, 26, 25, 12,  7, 21,  8,  9, 28, 15,\n",
       "       27, 35, 32, 23, 14, 30,  3, 29, 16,  0, 10, 19,  4, 18,  6, 17,  5,\n",
       "        2, 24, 69, 70, 71, 60, 62, 59, 45, 56, 41, 53, 40, 68, 49, 46, 42,\n",
       "       38, 61, 43, 51, 44, 55, 65, 37, 57, 54, 72, 64, 66, 36, 48, 47, 52,\n",
       "       39, 58, 50, 63, 67])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train['group_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0317594f4ca7a58f3da0e10364d22265ab9f70cd"
   },
   "source": [
    "Checking the number of trainnig samples per class. Highest is concrete and lowest is hard_tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "08f85fb1f8f567ba7a8d0fbb007ec5605a7d6452"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "ax = y_train['surface'].value_counts().plot(kind='bar',\n",
    "                                    figsize=(14,8),\n",
    "                                    title=\"Counting by surface\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "820cd388ac7337964bbb3536f0a6d53f21f7c1b3"
   },
   "source": [
    "To handle the length difference between the x_trai nand y_train, we roll up x_train such that it is the same size as y_train. We subsequently convert them to numpy arrays to pass into the deep learning keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "f220f915c9482677aa37e43b6a995c8edc1c3b98"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.drop(['row_id', \"series_id\", \"measurement_number\"], axis=1)\n",
    "y_train = y_train.drop(['group_id', \"series_id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "7a24b5a98b0dd9cb55c1cc2472b14fed66e79453"
   },
   "outputs": [],
   "source": [
    "x_train =x_train.values.reshape((3810, 128, 10))\n",
    "y_train =y_train.values.reshape((3810, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "31306efdc42f13f819467da05ffe96cdac1bff0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3810, 128, 10)\n",
      "(3810, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "7b6ab80a733b2723d7d467c62585d60d58a65aac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['concrete'],\n",
       "       ['concrete'],\n",
       "       ['concrete'],\n",
       "       ['soft_tiles']], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3eb182db33972d8a44c59f216f1ecd989c8eb91c"
   },
   "source": [
    "The labels are strings and hence need to be converted into numbers that a deep learning model can understand. Thankfully, keras does that for us as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "248bc82dd004797ec718e4186812810078a85a28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape is (3810,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "print('y_train shape is {}'.format(str(y_train.shape)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9c9fbd690a33fa1662cd242a214ca9afea1ceac7"
   },
   "source": [
    "Split the train data into train and validation files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "31c744f249eac6c169e422dd8a79001b47af1805"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3238, 128, 10) (3238,) (572, 128, 10) (572,)\n"
     ]
    }
   ],
   "source": [
    "x_tr, x_te,y_tr, y_te = train_test_split(x_train, y_train, test_size = 0.15)\n",
    "print(x_tr.shape, y_tr.shape, x_te.shape, y_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "aeafde4a4f0176059ec90df1ff72438c6a85bdd3"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, dropout=0.1, return_sequences = True,recurrent_dropout=0.1, input_shape=((128, 10))))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(9, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "b3dbf7b02b4e464cedfbe7743e7fe9e9c0061f8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128, 128)          71168     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 9)                 585       \n",
      "=================================================================\n",
      "Total params: 232,265\n",
      "Trainable params: 232,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "3737e6bbedcd14c89efa9b83a7aaff5634b209c6"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "3b24c41637f32cf8a5235b4fc873f31d6744f007"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3238 samples, validate on 572 samples\n",
      "Epoch 1/150\n",
      "3238/3238 [==============================] - 32s 10ms/step - loss: 2.0652 - acc: 0.1998 - val_loss: 2.0061 - val_acc: 0.2745\n",
      "Epoch 2/150\n",
      "3238/3238 [==============================] - 28s 9ms/step - loss: 1.9954 - acc: 0.2427 - val_loss: 1.9409 - val_acc: 0.2675\n",
      "Epoch 3/150\n",
      "3238/3238 [==============================] - 28s 9ms/step - loss: 1.8854 - acc: 0.2903 - val_loss: 1.7330 - val_acc: 0.3217\n",
      "Epoch 4/150\n",
      "3238/3238 [==============================] - 28s 9ms/step - loss: 1.7604 - acc: 0.3190 - val_loss: 1.7059 - val_acc: 0.3042\n",
      "Epoch 5/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.7144 - acc: 0.3289 - val_loss: 1.5765 - val_acc: 0.3374\n",
      "Epoch 6/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.7044 - acc: 0.3416 - val_loss: 1.5682 - val_acc: 0.3339\n",
      "Epoch 7/150\n",
      "3238/3238 [==============================] - 28s 9ms/step - loss: 1.6531 - acc: 0.3521 - val_loss: 1.5291 - val_acc: 0.4301\n",
      "Epoch 8/150\n",
      "3238/3238 [==============================] - 28s 9ms/step - loss: 1.6623 - acc: 0.3545 - val_loss: 1.5139 - val_acc: 0.3951\n",
      "Epoch 9/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.6133 - acc: 0.3743 - val_loss: 1.4514 - val_acc: 0.4406\n",
      "Epoch 10/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.5888 - acc: 0.3687 - val_loss: 1.4701 - val_acc: 0.4248\n",
      "Epoch 11/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.5488 - acc: 0.4009 - val_loss: 1.4291 - val_acc: 0.4755\n",
      "Epoch 12/150\n",
      "3238/3238 [==============================] - 28s 8ms/step - loss: 1.5240 - acc: 0.4030 - val_loss: 1.4459 - val_acc: 0.4545\n",
      "Epoch 13/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.4921 - acc: 0.4169 - val_loss: 1.3655 - val_acc: 0.4948\n",
      "Epoch 14/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.4123 - acc: 0.4608 - val_loss: 1.3348 - val_acc: 0.5192\n",
      "Epoch 15/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.4402 - acc: 0.4611 - val_loss: 1.2675 - val_acc: 0.5245\n",
      "Epoch 16/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.3852 - acc: 0.4830 - val_loss: 1.2263 - val_acc: 0.5664\n",
      "Epoch 17/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.3397 - acc: 0.5046 - val_loss: 1.2068 - val_acc: 0.5734\n",
      "Epoch 18/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.3141 - acc: 0.5090 - val_loss: 1.2475 - val_acc: 0.5472\n",
      "Epoch 19/150\n",
      "3238/3238 [==============================] - 28s 9ms/step - loss: 1.2688 - acc: 0.5259 - val_loss: 1.2996 - val_acc: 0.5350\n",
      "Epoch 20/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.2482 - acc: 0.5380 - val_loss: 1.1151 - val_acc: 0.5927\n",
      "Epoch 21/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.2622 - acc: 0.5361 - val_loss: 1.1958 - val_acc: 0.5717\n",
      "Epoch 22/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.3847 - acc: 0.4864 - val_loss: 1.2105 - val_acc: 0.5297\n",
      "Epoch 23/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.2907 - acc: 0.5213 - val_loss: 1.1713 - val_acc: 0.5612\n",
      "Epoch 24/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.2085 - acc: 0.5584 - val_loss: 1.1383 - val_acc: 0.5997\n",
      "Epoch 25/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.2500 - acc: 0.5451 - val_loss: 1.1524 - val_acc: 0.5682\n",
      "Epoch 26/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.1905 - acc: 0.5605 - val_loss: 1.1183 - val_acc: 0.5892\n",
      "Epoch 27/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.1660 - acc: 0.5800 - val_loss: 1.1447 - val_acc: 0.5682\n",
      "Epoch 28/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.1928 - acc: 0.5695 - val_loss: 1.1047 - val_acc: 0.5892\n",
      "Epoch 29/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.1673 - acc: 0.5720 - val_loss: 1.2367 - val_acc: 0.5629\n",
      "Epoch 30/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.1383 - acc: 0.5815 - val_loss: 1.1747 - val_acc: 0.5839\n",
      "Epoch 31/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.0926 - acc: 0.6050 - val_loss: 1.0019 - val_acc: 0.6556\n",
      "Epoch 32/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.0604 - acc: 0.6170 - val_loss: 1.0545 - val_acc: 0.6171\n",
      "Epoch 33/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.0668 - acc: 0.6053 - val_loss: 1.0375 - val_acc: 0.6101\n",
      "Epoch 34/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.2577 - acc: 0.5401 - val_loss: 1.1195 - val_acc: 0.5892\n",
      "Epoch 35/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.1130 - acc: 0.5939 - val_loss: 1.1696 - val_acc: 0.5839\n",
      "Epoch 36/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.0688 - acc: 0.6137 - val_loss: 1.0306 - val_acc: 0.6241\n",
      "Epoch 37/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.0739 - acc: 0.6072 - val_loss: 0.9898 - val_acc: 0.6538\n",
      "Epoch 38/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.0543 - acc: 0.6170 - val_loss: 0.9920 - val_acc: 0.6503\n",
      "Epoch 39/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.0138 - acc: 0.6282 - val_loss: 1.0366 - val_acc: 0.6189\n",
      "Epoch 40/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.0021 - acc: 0.6384 - val_loss: 0.9560 - val_acc: 0.6503\n",
      "Epoch 41/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.9956 - acc: 0.6313 - val_loss: 1.0065 - val_acc: 0.6469\n",
      "Epoch 42/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.0015 - acc: 0.6436 - val_loss: 0.9489 - val_acc: 0.6608\n",
      "Epoch 43/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.9576 - acc: 0.6433 - val_loss: 1.1013 - val_acc: 0.6154\n",
      "Epoch 44/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.9686 - acc: 0.6340 - val_loss: 0.9693 - val_acc: 0.6661\n",
      "Epoch 45/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.9564 - acc: 0.6532 - val_loss: 0.9583 - val_acc: 0.6696\n",
      "Epoch 46/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.9403 - acc: 0.6489 - val_loss: 1.0868 - val_acc: 0.6224\n",
      "Epoch 47/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 1.0029 - acc: 0.6282 - val_loss: 0.9995 - val_acc: 0.6626\n",
      "Epoch 48/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.9387 - acc: 0.6566 - val_loss: 0.8748 - val_acc: 0.7290\n",
      "Epoch 49/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.9024 - acc: 0.6705 - val_loss: 0.9188 - val_acc: 0.6993\n",
      "Epoch 50/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.9212 - acc: 0.6717 - val_loss: 0.8617 - val_acc: 0.7010\n",
      "Epoch 51/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.8661 - acc: 0.6782 - val_loss: 0.9995 - val_acc: 0.6486\n",
      "Epoch 52/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.8935 - acc: 0.6779 - val_loss: 0.8697 - val_acc: 0.6976\n",
      "Epoch 53/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.8757 - acc: 0.6705 - val_loss: 0.9596 - val_acc: 0.6696\n",
      "Epoch 54/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.8337 - acc: 0.6977 - val_loss: 0.8237 - val_acc: 0.7115\n",
      "Epoch 55/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.8297 - acc: 0.6905 - val_loss: 0.9354 - val_acc: 0.6731\n",
      "Epoch 56/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.8287 - acc: 0.6946 - val_loss: 0.8766 - val_acc: 0.6958\n",
      "Epoch 57/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.8288 - acc: 0.6936 - val_loss: 0.8566 - val_acc: 0.7080\n",
      "Epoch 58/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.8050 - acc: 0.7026 - val_loss: 0.8878 - val_acc: 0.6923\n",
      "Epoch 59/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.8074 - acc: 0.7078 - val_loss: 0.8211 - val_acc: 0.7010\n",
      "Epoch 60/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.8147 - acc: 0.6939 - val_loss: 0.8851 - val_acc: 0.6958\n",
      "Epoch 61/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.8110 - acc: 0.6933 - val_loss: 0.8295 - val_acc: 0.7185\n",
      "Epoch 62/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.7598 - acc: 0.7282 - val_loss: 0.8683 - val_acc: 0.6958\n",
      "Epoch 63/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.7751 - acc: 0.7156 - val_loss: 0.8824 - val_acc: 0.7133\n",
      "Epoch 64/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.7811 - acc: 0.7125 - val_loss: 0.8836 - val_acc: 0.7168\n",
      "Epoch 65/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.7463 - acc: 0.7221 - val_loss: 0.8671 - val_acc: 0.7150\n",
      "Epoch 66/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.7427 - acc: 0.7329 - val_loss: 0.7439 - val_acc: 0.7395\n",
      "Epoch 67/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.7405 - acc: 0.7211 - val_loss: 0.8111 - val_acc: 0.7220\n",
      "Epoch 68/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.7489 - acc: 0.7270 - val_loss: 0.8120 - val_acc: 0.7343\n",
      "Epoch 69/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.7338 - acc: 0.7230 - val_loss: 0.8219 - val_acc: 0.6976\n",
      "Epoch 70/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.7243 - acc: 0.7335 - val_loss: 0.8246 - val_acc: 0.7448\n",
      "Epoch 71/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.6913 - acc: 0.7449 - val_loss: 0.9201 - val_acc: 0.7150\n",
      "Epoch 72/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.7062 - acc: 0.7437 - val_loss: 0.8050 - val_acc: 0.7343\n",
      "Epoch 73/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.6919 - acc: 0.7443 - val_loss: 0.7614 - val_acc: 0.7483\n",
      "Epoch 74/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.6660 - acc: 0.7474 - val_loss: 0.7523 - val_acc: 0.7657\n",
      "Epoch 75/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.6589 - acc: 0.7576 - val_loss: 0.8248 - val_acc: 0.7150\n",
      "Epoch 76/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.6646 - acc: 0.7464 - val_loss: 0.8812 - val_acc: 0.7308\n",
      "Epoch 77/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.6761 - acc: 0.7529 - val_loss: 0.7679 - val_acc: 0.7325\n",
      "Epoch 78/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.7131 - acc: 0.7335 - val_loss: 0.8017 - val_acc: 0.7220\n",
      "Epoch 79/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.6566 - acc: 0.7641 - val_loss: 0.8512 - val_acc: 0.7308\n",
      "Epoch 80/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.6570 - acc: 0.7613 - val_loss: 0.7625 - val_acc: 0.7570\n",
      "Epoch 81/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.6298 - acc: 0.7705 - val_loss: 0.7574 - val_acc: 0.7395\n",
      "Epoch 82/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.6591 - acc: 0.7517 - val_loss: 0.7657 - val_acc: 0.7378\n",
      "Epoch 83/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.6832 - acc: 0.7539 - val_loss: 0.7830 - val_acc: 0.7185\n",
      "Epoch 84/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.6200 - acc: 0.7736 - val_loss: 0.7586 - val_acc: 0.7448\n",
      "Epoch 85/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.6228 - acc: 0.7690 - val_loss: 0.7351 - val_acc: 0.7570\n",
      "Epoch 86/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.6056 - acc: 0.7764 - val_loss: 0.9154 - val_acc: 0.7133\n",
      "Epoch 87/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.6207 - acc: 0.7681 - val_loss: 0.7430 - val_acc: 0.7570\n",
      "Epoch 88/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.6345 - acc: 0.7724 - val_loss: 0.8460 - val_acc: 0.7080\n",
      "Epoch 89/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.5849 - acc: 0.7823 - val_loss: 0.6649 - val_acc: 0.7867\n",
      "Epoch 90/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.6312 - acc: 0.7659 - val_loss: 0.9486 - val_acc: 0.7080\n",
      "Epoch 91/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.5932 - acc: 0.7801 - val_loss: 0.6803 - val_acc: 0.7780\n",
      "Epoch 92/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.6310 - acc: 0.7588 - val_loss: 0.8541 - val_acc: 0.7325\n",
      "Epoch 93/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.5887 - acc: 0.7829 - val_loss: 0.8056 - val_acc: 0.7430\n",
      "Epoch 94/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.5716 - acc: 0.7835 - val_loss: 0.7975 - val_acc: 0.7395\n",
      "Epoch 95/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.5795 - acc: 0.7888 - val_loss: 0.8438 - val_acc: 0.7430\n",
      "Epoch 96/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.5542 - acc: 0.7959 - val_loss: 0.7752 - val_acc: 0.7552\n",
      "Epoch 97/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.5493 - acc: 0.8014 - val_loss: 0.8961 - val_acc: 0.7343\n",
      "Epoch 98/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.5449 - acc: 0.8039 - val_loss: 0.7870 - val_acc: 0.7500\n",
      "Epoch 99/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.5596 - acc: 0.7952 - val_loss: 0.9028 - val_acc: 0.7133\n",
      "Epoch 100/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.5472 - acc: 0.7980 - val_loss: 0.9706 - val_acc: 0.7133\n",
      "Epoch 101/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.5430 - acc: 0.8014 - val_loss: 0.8901 - val_acc: 0.7343\n",
      "Epoch 102/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.5524 - acc: 0.7940 - val_loss: 0.7029 - val_acc: 0.7780\n",
      "Epoch 103/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.5542 - acc: 0.7940 - val_loss: 0.7932 - val_acc: 0.7308\n",
      "Epoch 104/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.5435 - acc: 0.8030 - val_loss: 0.8587 - val_acc: 0.7308\n",
      "Epoch 105/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.5212 - acc: 0.8061 - val_loss: 0.8839 - val_acc: 0.7378\n",
      "Epoch 106/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.5125 - acc: 0.8116 - val_loss: 0.8017 - val_acc: 0.7605\n",
      "Epoch 107/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.4975 - acc: 0.8187 - val_loss: 0.8535 - val_acc: 0.7535\n",
      "Epoch 108/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.5180 - acc: 0.8061 - val_loss: 0.9371 - val_acc: 0.7378\n",
      "Epoch 109/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.5280 - acc: 0.8107 - val_loss: 0.7946 - val_acc: 0.7587\n",
      "Epoch 110/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.5222 - acc: 0.8095 - val_loss: 0.8706 - val_acc: 0.7535\n",
      "Epoch 111/150\n",
      "3238/3238 [==============================] - 26s 8ms/step - loss: 0.5061 - acc: 0.8190 - val_loss: 0.9934 - val_acc: 0.7220\n",
      "Epoch 112/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.4852 - acc: 0.8317 - val_loss: 0.9056 - val_acc: 0.7587\n",
      "Epoch 113/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.4731 - acc: 0.8280 - val_loss: 1.0560 - val_acc: 0.7045\n",
      "Epoch 114/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.4800 - acc: 0.8345 - val_loss: 0.9246 - val_acc: 0.7413\n",
      "Epoch 115/150\n",
      "3238/3238 [==============================] - 26s 8ms/step - loss: 0.4956 - acc: 0.8218 - val_loss: 0.8380 - val_acc: 0.7395\n",
      "Epoch 116/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.5103 - acc: 0.8166 - val_loss: 0.8181 - val_acc: 0.7483\n",
      "Epoch 117/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.4359 - acc: 0.8400 - val_loss: 0.8990 - val_acc: 0.7500\n",
      "Epoch 118/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.4609 - acc: 0.8338 - val_loss: 0.7646 - val_acc: 0.7745\n",
      "Epoch 119/150\n",
      "3238/3238 [==============================] - 26s 8ms/step - loss: 0.4508 - acc: 0.8351 - val_loss: 0.8948 - val_acc: 0.7535\n",
      "Epoch 120/150\n",
      "3238/3238 [==============================] - 26s 8ms/step - loss: 0.4634 - acc: 0.8206 - val_loss: 0.9057 - val_acc: 0.7430\n",
      "Epoch 121/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.4382 - acc: 0.8403 - val_loss: 0.9125 - val_acc: 0.7622\n",
      "Epoch 122/150\n",
      "3238/3238 [==============================] - 26s 8ms/step - loss: 0.4633 - acc: 0.8255 - val_loss: 0.8273 - val_acc: 0.7587\n",
      "Epoch 123/150\n",
      "3238/3238 [==============================] - 27s 8ms/step - loss: 0.4630 - acc: 0.8286 - val_loss: 0.8571 - val_acc: 0.7325\n",
      "Epoch 124/150\n",
      "2432/3238 [=====================>........] - ETA: 6s - loss: 0.4240 - acc: 0.8462"
     ]
    }
   ],
   "source": [
    "model_fit = model.fit(x_tr, y_tr,\n",
    "                    batch_size=64,\n",
    "                    epochs=150,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_te, y_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cbab7cdb9c5902ffdded614734759b5bbac5a299"
   },
   "source": [
    "Pre-process the x_test in the same way as x_train to generate appropriate input data for the model to predict on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "44b4ed25a1b67b1fa0bad96f79b48ae1478ae5c5"
   },
   "outputs": [],
   "source": [
    "x_test = x_test.drop(['row_id', \"series_id\", \"measurement_number\"], axis=1)\n",
    "x_test =x_test.values.reshape((3816, 128, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "09006ef96ea69552c5d22afd04a8ff54252a39ec"
   },
   "source": [
    "Predict on the model and submit to the csv file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "d7335d91644f224cda86f275553544caa7b51cc1"
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(x_test)\n",
    "prediction=np.argmax(prediction, axis=1)\n",
    "y_preds = le.inverse_transform(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "fe630e6e48ef76248aec7f75d05ed7b87974fc56"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "submission['surface'] = y_preds\n",
    "submission.to_csv('lstm_with_Fully_connected_layers.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
